{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import absolute_import\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import esn_cell\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('india_surroundings_1mar2016 _28_feb_2017.csv')\n",
    "del df['IRIS ID'], df['Year'], df['Month'], df['Day'], df['Time UTC'], df['Region']\n",
    "df = df.iloc[::-1]\n",
    "#df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_test_ratio = .7\n",
    "train_size = int(df.shape[0] * train_test_ratio)\n",
    "train_data = df.iloc[:train_size]\n",
    "test_data = df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFrameMapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mapper = \u001b[43mDataFrameMapper\u001b[49m([\n\u001b[32m      2\u001b[39m        \u001b[38;5;66;03m# (['Region'], None),\u001b[39;00m\n\u001b[32m      3\u001b[39m         ([\u001b[33m'\u001b[39m\u001b[33mMag\u001b[39m\u001b[33m'\u001b[39m],sklearn.preprocessing.StandardScaler()),\n\u001b[32m      4\u001b[39m         ([\u001b[33m'\u001b[39m\u001b[33mLat\u001b[39m\u001b[33m'\u001b[39m],sklearn.preprocessing.StandardScaler()),\n\u001b[32m      5\u001b[39m         ([\u001b[33m'\u001b[39m\u001b[33mLon\u001b[39m\u001b[33m'\u001b[39m],sklearn.preprocessing.StandardScaler()),\n\u001b[32m      6\u001b[39m         ([\u001b[33m'\u001b[39m\u001b[33mDepth km\u001b[39m\u001b[33m'\u001b[39m],sklearn.preprocessing.StandardScaler()),\n\u001b[32m      7\u001b[39m         ([\u001b[33m'\u001b[39m\u001b[33mTimestamp\u001b[39m\u001b[33m'\u001b[39m], sklearn.preprocessing.StandardScaler()) \n\u001b[32m      8\u001b[39m     ],default = \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      9\u001b[39m train_data = mapper.fit_transform(train_data)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#train_data[['Mag','Lat','Lon','Timestamp','Depth km']] = train_data[['Mag','Lat','Lon','Timestamp','Depth km']].astype(float)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'DataFrameMapper' is not defined"
     ]
    }
   ],
   "source": [
    "mapper = DataFrameMapper([\n",
    "       # (['Region'], None),\n",
    "        (['Mag'],sklearn.preprocessing.StandardScaler()),\n",
    "        (['Lat'],sklearn.preprocessing.StandardScaler()),\n",
    "        (['Lon'],sklearn.preprocessing.StandardScaler()),\n",
    "        (['Depth km'],sklearn.preprocessing.StandardScaler()),\n",
    "        (['Timestamp'], sklearn.preprocessing.StandardScaler()) \n",
    "    ],default = None)\n",
    "train_data = mapper.fit_transform(train_data)\n",
    "#train_data[['Mag','Lat','Lon','Timestamp','Depth km']] = train_data[['Mag','Lat','Lon','Timestamp','Depth km']].astype(float)\n",
    "test_data = mapper.transform(test_data)\n",
    "#test_data[['Mag','Lat','Lon','Timestamp','Depth km']] = test_data[['Mag','Lat','Lon','Timestamp','Depth km']].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tr_size=500\n",
    "washout_size=15\n",
    "units=30\n",
    "connectivity=0.2\n",
    "scale=0.7\n",
    "num_features = 5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    data_t = tf.reshape(tf.constant(data), [1, , num_features])\n",
    "    esn = ESNCell(units, connectivity, scale)\n",
    "\n",
    "    print(\"Building graph...\")\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(esn, data_t, dtype=tf.float32)\n",
    "    washed = tf.squeeze(tf.slice(outputs, [0, washout_size, 0], [-1, -1, -1]))\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    print(\"Computing embeddings...\")\n",
    "    res = sess.run(washed)\n",
    "\n",
    "    print(\"Computing direct solution...\")\n",
    "    state = np.array(res)\n",
    "    tr_state = np.mat(state[:tr_size])\n",
    "    ts_state = np.mat(state[tr_size:])\n",
    "    wout = np.transpose(np.mat(data[washout_size+1:tr_size+washout_size+1]) * np.transpose(np.linalg.pinv(tr_state)))\n",
    "\n",
    "    print(\"Testing performance...\")\n",
    "    ts_out = np.mat((np.transpose(ts_state * wout).tolist())[0][:-1])\n",
    "    ts_y = np.mat(data[washout_size+tr_size+1:])\n",
    "\n",
    "    ts_mse = np.mean(np.square(ts_y - ts_out))\n",
    "\n",
    "    print(\"Test MSE: \" + str(ts_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_targets, test_outputs = \u001b[43mnp\u001b[49m.reshape(test_targets,(-\u001b[32m1\u001b[39m,\u001b[32m5\u001b[39m)), np.reshape(test_outputs,(-\u001b[32m1\u001b[39m,\u001b[32m5\u001b[39m)) \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[32m      3\u001b[39m total_error = r2_score(test_targets, test_outputs) \n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "test_targets, test_outputs = np.reshape(test_targets,(-1,5)), np.reshape(test_outputs,(-1,5)) \n",
    "from sklearn.metrics import r2_score\n",
    "total_error = r2_score(test_targets, test_outputs) \n",
    "print(\"total r2 score\", total_error)\n",
    "plt.axhline([total_error],0,1,label='overall score')\n",
    "indv_error_dict = {col:np.round(r2_score(test_targets[:,i], test_outputs[:,i]),3) for i, col in enumerate(df.columns)}\n",
    "print(\"r2 scores for individual variables\", indv_error_dict)\n",
    "plt.bar(range(len(indv_error_dict)), indv_error_dict.values())\n",
    "plt.xticks(range(len(indv_error_dict)), indv_error_dict.keys())\n",
    "plt.ylabel('r2 score')\n",
    "plt.xlabel('Predicted Variable')\n",
    "plt.legend()\n",
    "plt.savefig(\"test.eps\", format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "name": "esn.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
